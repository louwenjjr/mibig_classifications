{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sealed-tours",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this notebook I am prospecting how to gather chemical and bgc classes from mibigs. This is inspired by ClassifyNPDB.\n",
    "\n",
    "I will try to use the gnps classyfire api and see how many chemical classifications that results in, so the need for pyclassyfire is obsolete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "faced-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import glob\n",
    "import json\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recorded-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mibig_smiles_path exists is True\n"
     ]
    }
   ],
   "source": [
    "mibig_folder = \"/mnt/scratch/louwe015/mibig_json_2.0/\"\n",
    "\n",
    "base_path = \"/mnt/scratch/louwe015/NPLinker/classifying/mibig_classifications/\"\n",
    "mibig_smiles_path = os.path.join(base_path, \"files/All_MIBiG_compounds_with_SMILES_and_PMID_MAS.txt\")\n",
    "print(\"mibig_smiles_path exists is\", os.path.isfile(mibig_smiles_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-validation",
   "metadata": {},
   "source": [
    "## Read in mibig smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "scientific-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mibig_smiles(in_file: str) -> Dict[str, str]:\n",
    "    \"\"\"Load mibig smiles from file (tsv) and return {BGCid_Compound: smiles}\n",
    "    \"\"\"\n",
    "    compound_dict = {}\n",
    "    with open(in_file, 'r') as inf:\n",
    "        inf.readline() #ignore header\n",
    "        for line in inf:\n",
    "            line = line.split('\\t')\n",
    "            compound_id = line[0]+\"_\"+line[1]\n",
    "            structure = line[2]\n",
    "            if compound_id in compound_dict:\n",
    "                raise ValueError(\"Duplication in mibig smiles file, please check file\")\n",
    "            if len(structure) > 0:\n",
    "                compound_dict[compound_id] = structure\n",
    "    return compound_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alternative-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dict = load_mibig_smiles(mibig_smiles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "allied-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BGC0000001_abyssomicin C',\n",
       "  'CC1C[C@]23OC(=O)C4=C2OC1C(O)C3\\\\C=C/C(=O)[C@@H](C)C[C@@H](C)C4=O'),\n",
       " ('BGC0000001_atrop-abyssomicin C',\n",
       "  'CC1CC23OC(=O)C4=C2OC1C(O)C3\\\\C=C/C(=O)C(C)CC(C)C4=O'),\n",
       " ('BGC0000002_aculeximycin',\n",
       "  'CCCC(O[C@H]1C[C@](C)(N)[C@H](O)[C@H](C)O1)C(C)C(O)C(CC)\\\\C=C\\\\C(O)C(C)C1C\\\\C=C(C)\\\\C(O)C(C)C(CC(O)C(C)C(O)CC2CC(O)C(O)C(O)(CC(O[C@@H]3O[C@H](C)[C@@H](O)[C@H](O[C@H]4C[C@@H](N)[C@H](O)[C@@H](C)O4)[C@H]3O[C@@H]3O[C@H](C)[C@@H](O)[C@H](O)[C@H]3O)C(C)CCC(O)CC(O)C\\\\C=C(CC)\\\\C(=O)O1)O2)O[C@@H]1O[C@H](CO)[C@@H](O)[C@H](O)[C@@H]1O'),\n",
       " ('BGC0000003_AF-toxin',\n",
       "  'CCC(C)C(C(=O)OC(/C=C/C=C/C=C/C(=O)O)C1(CO1)C)OC(=O)C(C(C)(C)O)O'),\n",
       " ('BGC0000004_aflatoxin G1',\n",
       "  '[H][C@@]12OC=C[C@]1([H])C1=C(O2)C=C(OC)C2=C1OC(=O)C1=C2CCOC1=O')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(comp_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-arthritis",
   "metadata": {},
   "source": [
    "## Use GNPS api to get ClassyFire results from smiles\n",
    "- Try to get it from smiles\n",
    "- If result is empty; convert to inchikey through gnps as well\n",
    "- get CF result from inchikey\n",
    "\n",
    "\n",
    "### First try just using smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "occasional-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered 1766 results, missing 346 results\n"
     ]
    }
   ],
   "source": [
    "# just trying with smiles\n",
    "\n",
    "result_list = []\n",
    "for i, (np, smiles) in enumerate(comp_dict.items()):\n",
    "    url_base = \"https://gnps-structure.ucsd.edu/classyfire?smiles=\"\n",
    "    smiles = smiles.strip(' ')\n",
    "    safe_smiles = urllib.parse.quote(smiles)  # url encoding\n",
    "    url = url_base + safe_smiles\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as inf:\n",
    "            smiles_result = inf.read()\n",
    "    except urllib.error.HTTPError:\n",
    "        # apparently the smiles request failed\n",
    "        smiles_result = None\n",
    "        superclass = None  # remove later when directing to inchikey\n",
    "\n",
    "    if smiles_result is not None:\n",
    "        cf_json = json.loads(smiles_result)  # make a function that gathers result from json, no matter the source\n",
    "        superclass_dict = cf_json.get(\"superclass\", None)\n",
    "        superclass = None\n",
    "        if superclass_dict:\n",
    "            superclass = superclass_dict.get(\"name\", None)\n",
    "        \n",
    "    result_list.append(superclass)\n",
    "\n",
    "missing_res_num = len([elem for elem in result_list if elem is None])\n",
    "print(f\"Gathered {len(result_list)-missing_res_num} results, missing {missing_res_num} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-declaration",
   "metadata": {},
   "source": [
    "### First lookup smiles, then try via lookup of inchikey\n",
    "apparently this doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "foster-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered 1766 results, missing 346 results\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "for i, (np, smiles) in enumerate(comp_dict.items()):\n",
    "    superclass = None\n",
    "    \n",
    "    # lookup CF with smiles\n",
    "    url_base = \"https://gnps-structure.ucsd.edu/classyfire?smiles=\"\n",
    "    smiles = smiles.strip(' ')\n",
    "    safe_smiles = urllib.parse.quote(smiles)  # url encoding\n",
    "    url = url_base + safe_smiles\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as inf:\n",
    "            smiles_result = inf.read()\n",
    "    except urllib.error.HTTPError:\n",
    "        # apparently the smiles request failed\n",
    "        smiles_result = None\n",
    "    \n",
    "    # read CF result\n",
    "    if smiles_result is not None:\n",
    "        cf_json = json.loads(smiles_result)  # make a function that gathers result from json, no matter the source\n",
    "        superclass_dict = cf_json.get(\"superclass\", None)\n",
    "        if superclass_dict:\n",
    "            superclass = superclass_dict.get(\"name\", None)\n",
    "    \n",
    "    \n",
    "    if superclass is None:\n",
    "        # lookup inchikey from smiles\n",
    "        url_base = \"https://gnps-structure.ucsd.edu/inchikey?smiles=\"\n",
    "        url = url_base + safe_smiles\n",
    "        try:\n",
    "            with urllib.request.urlopen(url) as inf:\n",
    "                inchi_result = str(inf.read(), 'utf-8')\n",
    "#                 print(inchi_result)\n",
    "        except urllib.error.HTTPError:\n",
    "            # apparently the inchi request failed\n",
    "            inchi_result = None\n",
    "        \n",
    "        # do CF lookup with inchikey\n",
    "        if inchi_result is not None:\n",
    "            url = f\"https://gnps-classyfire.ucsd.edu/entities/{inchi_result}.json\"\n",
    "#             print(url)\n",
    "            try:\n",
    "                with urllib.request.urlopen(url) as inf:\n",
    "                    inchi_cf_result = inf.read()\n",
    "            except urllib.error.HTTPError:\n",
    "                # apparently the inchi request failed\n",
    "                inchi_cf_result = None\n",
    "            \n",
    "            # read CF result from inchikey lookup\n",
    "            if inchi_cf_result is not None:\n",
    "                cf_json = json.loads(inchi_cf_result)  # make a function that gathers result from json, no matter the source\n",
    "                superclass_dict = cf_json.get(\"superclass\", None)\n",
    "                if superclass_dict:\n",
    "                    superclass = superclass_dict.get(\"name\", None)\n",
    "\n",
    "    result_list.append(superclass)\n",
    "\n",
    "missing_res_num = len([elem for elem in result_list if elem is None])\n",
    "print(f\"Gathered {len(result_list)-missing_res_num} results, missing {missing_res_num} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-ukraine",
   "metadata": {},
   "source": [
    "### Try also getting inchikey from rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "result_list = []\n",
    "for i, (np, smiles) in enumerate(comp_dict.items()):\n",
    "    superclass = None\n",
    "    \n",
    "    # lookup CF with smiles\n",
    "    url_base = \"https://gnps-structure.ucsd.edu/classyfire?smiles=\"\n",
    "    smiles = smiles.strip(' ')\n",
    "    safe_smiles = smiles #urllib.parse.quote(smiles)  # url encoding\n",
    "    url = url_base + safe_smiles\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as inf:\n",
    "            smiles_result = inf.read()\n",
    "    except urllib.error.HTTPError:\n",
    "        # apparently the smiles request failed\n",
    "        smiles_result = None\n",
    "    \n",
    "    # read CF result\n",
    "    if smiles_result is not None:\n",
    "        cf_json = json.loads(smiles_result)  # make a function that gathers result from json, no matter the source\n",
    "        superclass_dict = cf_json.get(\"superclass\", None)\n",
    "        if superclass_dict:\n",
    "            superclass = superclass_dict.get(\"name\", None)\n",
    "    \n",
    "    \n",
    "    if superclass is None:\n",
    "        # lookup inchikey from smiles\n",
    "        url_base = \"https://gnps-structure.ucsd.edu/inchikey?smiles=\"\n",
    "        url = url_base + safe_smiles\n",
    "        try:\n",
    "            with urllib.request.urlopen(url) as inf:\n",
    "                inchi_result = str(inf.read(), 'utf-8')\n",
    "#                 print(inchi_result)\n",
    "        except urllib.error.HTTPError:\n",
    "            # apparently the inchi request failed\n",
    "            inchi_result = None\n",
    "        \n",
    "        # do CF lookup with inchikey\n",
    "        if inchi_result is not None:\n",
    "            url = f\"https://gnps-classyfire.ucsd.edu/entities/{inchi_result}.json\"\n",
    "#             print(url)\n",
    "            try:\n",
    "                with urllib.request.urlopen(url) as inf:\n",
    "                    inchi_cf_result = inf.read()\n",
    "            except urllib.error.HTTPError:\n",
    "                # apparently the inchi request failed\n",
    "                inchi_cf_result = None\n",
    "            \n",
    "            # read CF result from inchikey lookup\n",
    "            if inchi_cf_result is not None:\n",
    "                cf_json = json.loads(inchi_cf_result)  # make a function that gathers result from json, no matter the source\n",
    "                superclass_dict = cf_json.get(\"superclass\", None)\n",
    "                if superclass_dict:\n",
    "                    superclass = superclass_dict.get(\"name\", None)\n",
    "    \n",
    "    # do a last try with inchikey from rdkit\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    rdkit_smiles = Chem.MolToSmiles(m, kekuleSmiles=False,isomericSmiles=False)\n",
    "    m = Chem.MolFromSmiles(rdkit_smiles)\n",
    "    rdkit_inchi = Chem.inchi.MolToInchiKey(m)\n",
    "    print(rdkit_smiles, rdkit_inchi)\n",
    "\n",
    "    result_list.append(superclass)\n",
    "    break\n",
    "\n",
    "missing_res_num = len([elem for elem in result_list if elem is None])\n",
    "print(f\"Gathered {len(result_list)-missing_res_num} results, missing {missing_res_num} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-sight",
   "metadata": {},
   "source": [
    "## Make some functions\n",
    "- do_url_request(url: str) -> [bytes, None]\n",
    "- get_json_cf_results(raw_json: bytes, wanted_info_list: List[str]) -> List[str]\n",
    "- master func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_url_request(url: str) -> [bytes, None]:\n",
    "    \"\"\"Do url request and return opened .read() object or None if HTTPError is raised\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url:\n",
    "        Url to access\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as inf:\n",
    "            result = inf.read()\n",
    "    except urllib.error.HTTPError:\n",
    "        # apparently the request failed\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "def get_json_cf_results(raw_json: bytes, wanted_keys_list_name: List[str] = [\"superclass\"]) -> List[str]:\n",
    "    \"\"\"Read bytes version of json str, extract the keys in wanted_keys_list_name in order\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_json:\n",
    "        Json str as a bytes object containing ClassyFire information\n",
    "    wanted_keys_list_name:\n",
    "        Keys to extract from the json, they all have a 'name' value in the json\n",
    "    \"\"\"\n",
    "    wanted_info = []\n",
    "    cf_json = json.loads(raw_json)\n",
    "    for key in wanted_keys_list_name:\n",
    "        info_dict = cf_json.get(key, \"\")\n",
    "        if info_dict:\n",
    "            info = info_dict.get('name', \"\")\n",
    "    wanted_info.append(info)\n",
    "    \n",
    "    return wanted_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
